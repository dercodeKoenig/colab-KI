{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_KI (2) (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrToffel/colab-KI/blob/main/Text_KI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umq9s-r0EMy_"
      },
      "source": [
        "KI entscheidet ob ein Text richtig oder eine sinnlose Zeichenkombination ist<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QPSquSX3zEa"
      },
      "source": [
        "1: Trainingstext laden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbhr2tnx3rt0",
        "outputId": "ca9cda38-007a-45a9-d2c7-424cf51d5342"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/MrToffel/colab-KI/main/in.txt       #trainingstext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-19 15:56:42--  https://raw.githubusercontent.com/MrToffel/colab-KI/main/in.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 446043 (436K) [text/plain]\n",
            "Saving to: ‘in.txt’\n",
            "\n",
            "\rin.txt                0%[                    ]       0  --.-KB/s               \rin.txt              100%[===================>] 435.59K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-03-19 15:56:42 (23.3 MB/s) - ‘in.txt’ saved [446043/446043]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY-3wSsw38r1"
      },
      "source": [
        "2: Imports ausführen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt5rlA_E3794"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBNGk2vV4MWP"
      },
      "source": [
        "3: Textdatei lesen und verschiedenen Buchstaben eine Id zuweisen\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb_MFJ3E4QLf",
        "outputId": "048f3c0a-01e7-4837-db33-da00899f5f97"
      },
      "source": [
        "raw_text=str(open(\"in.txt\").read()) #alle zeichen hier rein\n",
        "raw_text2=\"QWERTZUIOPÜ*'ASDFGHJKLÖÄYXCVBNM;:_qwertzuiopü+#asdfghjklöäyxcvbnm,.-<>|@1234567890ß!\\\"§$%&/()=? \\n»«~+*\\\\—½{}[]è\" #alle zeichen hier rein\n",
        "chars = sorted(list(set(raw_text2)))\n",
        "print(chars)\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Vocab: \", n_vocab)\n",
        "n_chars = len(raw_text)\n",
        "print (\"Total Characters: \", n_chars)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '§', '«', '»', '½', 'Ä', 'Ö', 'Ü', 'ß', 'ä', 'è', 'ö', 'ü', '—']\n",
            "Total Vocab:  107\n",
            "Total Characters:  437677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbMmgCoC4xsb"
      },
      "source": [
        "4: Text in kleine Ausschnitte zerhacken mit der Länge seq_length und Eingabe-Ausgabe-Paare generieren. <br>\n",
        "Um dem Modell auch falschen Text zu zeigen wird für jeden wahren String auch ein Falscher mit zufälligen Zeichen aus chars erstellt. <br>So bekommt das Modell die gleiche Zahl an richtigem und falschem Text zum üben"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5OZ0kWa6IVZ",
        "outputId": "73a83f2d-a2f5-41a0-b018-64b1599193b9"
      },
      "source": [
        "seq_length = 5\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(n_chars-seq_length):\n",
        "    data=raw_text[i:i+seq_length];\n",
        "    random_string = ''\n",
        "    for _ in range(seq_length):\n",
        "        random_integer = random.randint(0,n_vocab-1)\n",
        "        random_string += (int_to_char[random_integer])\n",
        "        \n",
        "    dataX+=data\n",
        "    dataX+=random_string\n",
        "    dataY+=[1]\n",
        "    dataY+=[0]\n",
        "\n",
        "dataX=np.reshape(np.array(dataX),(int(len(dataX)/seq_length),seq_length)) #reshape in [Anzahl, Länge einer Sequenz]\n",
        "Y=np.array(dataY)\n",
        "\n",
        "print(\"X:\")\n",
        "print(dataX)\n",
        "print(\"\")\n",
        "print(\"Y:\")\n",
        "print(Y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X:\n",
            "[['M' 'ä' 'n' 'n' 'e']\n",
            " ['5' ' ' '/' 'a' '3']\n",
            " ['ä' 'n' 'n' 'e' 'r']\n",
            " ...\n",
            " [']' '-' 'd' 'l' \"'\"]\n",
            " ['i' 'c' 'h' 't' 'e']\n",
            " ['%' 'x' '1' 'D' '~']]\n",
            "\n",
            "Y:\n",
            "[1 0 1 ... 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmPlluwK6-TH"
      },
      "source": [
        "5: Jeden Buchstaben in seine Id umwandeln"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81bpVWzF7EEm",
        "outputId": "0dea3ffb-902b-4997-b975-5befdd56de23"
      },
      "source": [
        "\n",
        "X = []\n",
        "for i in range(len(dataX)):\n",
        "  for o in range(len(dataX[i])):\n",
        "    X+=[char_to_int[dataX[i][o]]]\n",
        "\n",
        "X = np.reshape(X, (int(len(X)/seq_length), seq_length))\n",
        "print(X)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 46 102  77  77  68]\n",
            " [ 22   1  16  64  20]\n",
            " [102  77  77  68  81]\n",
            " ...\n",
            " [ 62  14  67  75   8]\n",
            " [ 72  66  71  83  68]\n",
            " [  6  87  18  37  93]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x3zQ_DG6JGX"
      },
      "source": [
        "6: One-hot-encoding durchführen.\n",
        "Beim one-hot-encoding werden Werte aus vielen 0 und einer 1 dargestellt.<br>\n",
        "Zb [\"a\",\"b\",\"c\"] wird zu [[0,0,1],[0,1,0],[1,0,0]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsAVE7uZ7vwy"
      },
      "source": [
        "X = to_categorical(X,num_classes=n_vocab)\n",
        "# reshape in [Anzahl, Länge der Sequenz, Länge der one-hot-encode-vectoren]\n",
        "X = np.reshape(X, (int(len(X)), seq_length, n_vocab))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whT-Qv457ySm"
      },
      "source": [
        "7: Modell erstellen. Testweise kann als LSTM auch GRU verwendet werden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOiEgcJ7pp9c",
        "outputId": "05453bad-6edb-4c35-88c7-e0ea4c12a65c"
      },
      "source": [
        "filepath=\"weights.hdf5\"\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(seq_length, n_vocab),return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(64,return_sequences=False))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "try:\n",
        "  model.load_weights(filepath)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 5, 32)             17920     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 5, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 42,882\n",
            "Trainable params: 42,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah_wukQs7_wR"
      },
      "source": [
        "8: Modell trainieren<br>Wenn du das Modell oben runtergeladen hast kannst du diesen Schritt überspringen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D88tdPpt8B7i",
        "outputId": "11e3a509-a633-413d-c0a0-8eac8aa6fd32"
      },
      "source": [
        "# checkpoint festlegen\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "model.fit(X, Y, epochs=10, batch_size=128,verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6839/6839 [==============================] - 65s 5ms/step - loss: 0.0511\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.02216, saving model to weights.hdf5\n",
            "Epoch 2/10\n",
            "6839/6839 [==============================] - 32s 5ms/step - loss: 0.0088\n",
            "\n",
            "Epoch 00002: loss improved from 0.02216 to 0.00806, saving model to weights.hdf5\n",
            "Epoch 3/10\n",
            "6839/6839 [==============================] - 31s 5ms/step - loss: 0.0060\n",
            "\n",
            "Epoch 00003: loss improved from 0.00806 to 0.00571, saving model to weights.hdf5\n",
            "Epoch 4/10\n",
            "6839/6839 [==============================] - 31s 5ms/step - loss: 0.0047\n",
            "\n",
            "Epoch 00004: loss improved from 0.00571 to 0.00451, saving model to weights.hdf5\n",
            "Epoch 5/10\n",
            "6839/6839 [==============================] - 31s 5ms/step - loss: 0.0037\n",
            "\n",
            "Epoch 00005: loss improved from 0.00451 to 0.00374, saving model to weights.hdf5\n",
            "Epoch 6/10\n",
            "6839/6839 [==============================] - 31s 5ms/step - loss: 0.0033\n",
            "\n",
            "Epoch 00006: loss improved from 0.00374 to 0.00328, saving model to weights.hdf5\n",
            "Epoch 7/10\n",
            "6839/6839 [==============================] - 31s 5ms/step - loss: 0.0027\n",
            "\n",
            "Epoch 00007: loss improved from 0.00328 to 0.00288, saving model to weights.hdf5\n",
            "Epoch 8/10\n",
            "6839/6839 [==============================] - 31s 4ms/step - loss: 0.0024\n",
            "\n",
            "Epoch 00008: loss improved from 0.00288 to 0.00255, saving model to weights.hdf5\n",
            "Epoch 9/10\n",
            "6839/6839 [==============================] - 30s 4ms/step - loss: 0.0023\n",
            "\n",
            "Epoch 00009: loss improved from 0.00255 to 0.00223, saving model to weights.hdf5\n",
            "Epoch 10/10\n",
            "6839/6839 [==============================] - 30s 4ms/step - loss: 0.0020\n",
            "\n",
            "Epoch 00010: loss improved from 0.00223 to 0.00201, saving model to weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb4c5402390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4SyeZu48Q6l"
      },
      "source": [
        "9: Auswertung"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mI5Uoik8SQ7",
        "outputId": "bbdbcf92-f436-47a8-8d53-57652dfeefc8"
      },
      "source": [
        "while True:\n",
        "  eingabe = input(\"text: \")\n",
        "  if(eingabe==\"ende\"):\n",
        "    break\n",
        "  n_chars = len(eingabe)\n",
        "  print (\"Buchatsben: \", n_chars)\n",
        "  dataX = []\n",
        "  for i in range(n_chars-seq_length):\n",
        "    data=eingabe[i:i+seq_length];\n",
        "    dataX+=data\n",
        "  dataX=np.reshape(np.array(dataX),(int(len(dataX)/seq_length),seq_length))\n",
        "  Xeingabe = []\n",
        "  for i in range(len(dataX)):\n",
        "    for o in range(len(dataX[i])):\n",
        "      Xeingabe+=[char_to_int[dataX[i][o]]]\n",
        "  Xeingabe = to_categorical(Xeingabe,num_classes=n_vocab)\n",
        "\n",
        "  # reshape X to be [samples, time steps, features]\n",
        "  Xeingabe = np.reshape(Xeingabe, (int(len(Xeingabe)/seq_length), seq_length, n_vocab))\n",
        "  wahr = 0.0\n",
        "  falsch = 0.0\n",
        "  gesamt = 0\n",
        "  for i in Xeingabe:\n",
        "    gesamt+=1\n",
        "    Xeingabe=np.reshape(np.array(i),(1,seq_length,n_vocab))\n",
        "    res = model.predict(Xeingabe)\n",
        "    \n",
        "    wahr += res[0][1]\n",
        "    falsch +=res[0][0]\n",
        "  \n",
        "  print(\"Bewertung Text: \",((wahr - falsch)/gesamt))\n",
        "  print(\"\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: ohibokjdbmfoybdpf\n",
            "Buchatsben:  17\n",
            "Bewertung Text:  -0.49505784984503237\n",
            "\n",
            "text: Hallo, das ist ein Test\n",
            "Buchatsben:  23\n",
            "Bewertung Text:  0.9997712402930661\n",
            "\n",
            "text: ende\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}