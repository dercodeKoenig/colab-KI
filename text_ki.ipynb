{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-ki",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGWfo/zXgSDl4Gzl7kcUxq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dercodeKoenig/colab-KI/blob/main/text_ki.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_EYboqjG_6k"
      },
      "source": [
        "KI entscheidet ob ein Text richtig oder eine sinnlose Zeichenkombination ist<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3Gy13_CHCkt"
      },
      "source": [
        "1: Trainingstext laden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxZR_8hoHD1H"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/dercodeKoenig/colab-KI/main/in.txt       #trainingstext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh0JToBYHFcj"
      },
      "source": [
        "2: Imports ausführen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAt4l0iMHG-N"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TszZeJHtHKK4"
      },
      "source": [
        "3: Textdatei lesen und verschiedenen Buchstaben eine Id zuweisen\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or2bF3obHLph"
      },
      "source": [
        "raw_text=str(open(\"in.txt\").read()) #alle zeichen hier rein\n",
        "raw_text2=\"QWERTZUIOPÜ*'ASDFGHJKLÖÄYXCVBNM;:_qwertzuiopü+#asdfghjklöäyxcvbnm,.-<>|@1234567890ß!\\\"§$%&/()=? \\n»«~+*\\\\—½{}[]è\" #alle zeichen hier rein\n",
        "chars = sorted(list(set(raw_text2)))\n",
        "print(chars)\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Vocab: \", n_vocab)\n",
        "n_chars = len(raw_text)\n",
        "print (\"Total Characters: \", n_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_rN3AVQHO5e"
      },
      "source": [
        "4: Text in kleine Ausschnitte zerhacken mit der Länge seq_length und Eingabe-Ausgabe-Paare generieren. <br>\n",
        "Um dem Modell auch falschen Text zu zeigen wird für jeden wahren String auch ein Falscher mit zufälligen Zeichen aus chars erstellt. <br>So bekommt das Modell die gleiche Zahl an richtigem und falschem Text zum üben"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZz_HrUkHQ3M"
      },
      "source": [
        "seq_length = 5\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(n_chars-seq_length):\n",
        "    data=raw_text[i:i+seq_length];\n",
        "    random_string = ''\n",
        "    for _ in range(seq_length):\n",
        "        random_integer = random.randint(0,n_vocab-1)\n",
        "        random_string += (int_to_char[random_integer])\n",
        "        \n",
        "    dataX+=data\n",
        "    dataX+=random_string\n",
        "    dataY+=[1]\n",
        "    dataY+=[0]\n",
        "\n",
        "dataX=np.reshape(np.array(dataX),(int(len(dataX)/seq_length),seq_length)) #reshape in [Anzahl, Länge einer Sequenz]\n",
        "Y=np.array(dataY)\n",
        "\n",
        "print(\"X:\")\n",
        "print(dataX)\n",
        "print(\"\")\n",
        "print(\"Y:\")\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWVNl6MXHSvN"
      },
      "source": [
        "5: Jeden Buchstaben in seine Id umwandeln"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yc5d2E8HVLN"
      },
      "source": [
        "\n",
        "X = []\n",
        "for i in range(len(dataX)):\n",
        "  for o in range(len(dataX[i])):\n",
        "    X+=[char_to_int[dataX[i][o]]]\n",
        "\n",
        "X = np.reshape(X, (int(len(X)/seq_length), seq_length))\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ls29JPHZPV"
      },
      "source": [
        "6: One-hot-encoding durchführen.\n",
        "Beim one-hot-encoding werden Werte aus vielen 0 und einer 1 dargestellt.<br>\n",
        "Zb [\"a\",\"b\",\"c\"] wird zu [[0,0,1],[0,1,0],[1,0,0]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6j-uWmqHa_1"
      },
      "source": [
        "X = to_categorical(X,num_classes=n_vocab)\n",
        "# reshape in [Anzahl, Länge der Sequenz, Länge der one-hot-encode-vectoren]\n",
        "X = np.reshape(X, (int(len(X)), seq_length, n_vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SKo9TYzHd-G"
      },
      "source": [
        "7: Modell erstellen. Testweise kann als LSTM auch GRU verwendet werden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGvXxI86HfCL"
      },
      "source": [
        "filepath=\"weights.hdf5\"\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(seq_length, n_vocab),return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(64,return_sequences=False))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "try:\n",
        "  model.load_weights(filepath)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMdGMbdDHhfV"
      },
      "source": [
        "8: Modell trainieren"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAydvkfnHi7J"
      },
      "source": [
        "# checkpoint festlegen\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "model.fit(X, Y, epochs=10, batch_size=128,verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE8qlaylHk1x"
      },
      "source": [
        "9: Auswertung"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu5YRwwBHl6J"
      },
      "source": [
        "while True:\n",
        "  eingabe = input(\"text: \")\n",
        "  if(eingabe==\"ende\"):\n",
        "    break\n",
        "  n_chars = len(eingabe)\n",
        "  print (\"Buchatsben: \", n_chars)\n",
        "  dataX = []\n",
        "  for i in range(n_chars-seq_length):\n",
        "    data=eingabe[i:i+seq_length];\n",
        "    dataX+=data\n",
        "  dataX=np.reshape(np.array(dataX),(int(len(dataX)/seq_length),seq_length))\n",
        "  Xeingabe = []\n",
        "  for i in range(len(dataX)):\n",
        "    for o in range(len(dataX[i])):\n",
        "      Xeingabe+=[char_to_int[dataX[i][o]]]\n",
        "  Xeingabe = to_categorical(Xeingabe,num_classes=n_vocab)\n",
        "\n",
        "  # reshape X to be [samples, time steps, features]\n",
        "  Xeingabe = np.reshape(Xeingabe, (int(len(Xeingabe)/seq_length), seq_length, n_vocab))\n",
        "  wahr = 0.0\n",
        "  falsch = 0.0\n",
        "  gesamt = 0\n",
        "  for i in Xeingabe:\n",
        "    gesamt+=1\n",
        "    Xeingabe=np.reshape(np.array(i),(1,seq_length,n_vocab))\n",
        "    res = model.predict(Xeingabe)\n",
        "    \n",
        "    wahr += res[0][1]\n",
        "    falsch +=res[0][0]\n",
        "  \n",
        "  print(\"Bewertung Text: \",((wahr - falsch)/gesamt))\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}