{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan-TPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1A5XGIs9hhqBxCs40Njs2Wt6MCfznz1ML",
      "authorship_tag": "ABX9TyOhbFtJ4Pzkus4lZO2t8X96",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dercodeKoenig/colab-KI/blob/main/gan-TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L907QAfGlueU",
        "outputId": "f98b83e1-581d-4457-a5a9-9dc7c97b520a"
      },
      "source": [
        "%cd /content/drive/MyDrive/\n",
        "#!rm -r outputs\n",
        "\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import cv2\n",
        "from IPython import display\n",
        "\n",
        "train_images_cartoon = []\n",
        "small_images_cartoon = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "  train_images_cartoon = np.load(\"npfilet.npy\")\n",
        "  small_images_cartoon = np.load(\"npfiles.npy\")\n",
        "except:\n",
        "  %cd /content\n",
        "  os.system(\"git clone https://github.com/dercodeKoenig/cartoon-faces.git\")\n",
        "  train_images_cartoon = []\n",
        "  small_images_cartoon = []\n",
        "  z=0\n",
        "  total = len(os.listdir(\"cartoon-faces\"))\n",
        "  max=512*100\n",
        "  files = os.listdir(\"cartoon-faces\")\n",
        "  while(True):\n",
        "    if(z>=max):\n",
        "      break\n",
        "    print(\"\\r\" + str(z) + \" / \" + str(51200),end=\"\")\n",
        "    try:\n",
        "      img = cv2.imread(\"cartoon-faces/\"+files[z])\n",
        "\n",
        "      img1 = img.copy()\n",
        "      img3 = cv2.resize(img1, (64,64))\n",
        "      img3 = cv2.blur(img3,(7,7))\n",
        "      \n",
        "    \n",
        "      Z = img3.reshape((-1,3))\n",
        "      # convert to np.float32\n",
        "      Z = np.float32(Z)\n",
        "      # define criteria, number of clusters(K) and apply kmeans()\n",
        "      criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "      K = 4\n",
        "      ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
        "      # Now convert back into uint8, and make original image\n",
        "      center = np.uint8(center)\n",
        "      res = center[label.flatten()]\n",
        "      res2 = res.reshape((img3.shape))\n",
        "\n",
        "      small_images_cartoon.append(res2)\n",
        "\n",
        "\n",
        "      img1 = img.copy()\n",
        "      img2 = cv2.resize(img1, (64,64))\n",
        "      train_images_cartoon.append(img2)\n",
        "    \n",
        "    except:\n",
        "      print(\"error: \")\n",
        "      try:\n",
        "        print(\" cartoon-faces/\"+files[z])\n",
        "      except:\n",
        "        pass\n",
        "      max+=1\n",
        "\n",
        "    z+=1\n",
        "  print(\"\")\n",
        "\n",
        "  train_images_cartoon = np.array(train_images_cartoon,dtype=object)\n",
        "  train_images_cartoon = train_images_cartoon.reshape(train_images_cartoon.shape[0], 64, 64, 3).astype('float32')\n",
        "  train_images_cartoon = (train_images_cartoon - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
        "\n",
        "  small_images_cartoon = np.array(small_images_cartoon,dtype=object)\n",
        "  small_images_cartoon = small_images_cartoon.reshape(small_images_cartoon.shape[0], 64, 64, 3).astype('float32')\n",
        "  small_images_cartoon = (small_images_cartoon - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
        "\n",
        "  %cd /content/drive/MyDrive/\n",
        "  np.save(\"npfilet\", train_images_cartoon)\n",
        "  np.save(\"npfiles\", small_images_cartoon)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "test_img = small_images_cartoon[0:20]\n",
        "\n",
        "print(train_images_cartoon.shape)\n",
        "train_images_cartoon1=train_images_cartoon[0:int(1*train_images_cartoon.shape[0]/4)]\n",
        "train_images_cartoon2=train_images_cartoon[int(1*train_images_cartoon.shape[0]/4):int(2*train_images_cartoon.shape[0]/4)]\n",
        "train_images_cartoon3=train_images_cartoon[int(2*train_images_cartoon.shape[0]/4):int(3*train_images_cartoon.shape[0]/4)]\n",
        "train_images_cartoon4=train_images_cartoon[int(3*train_images_cartoon.shape[0]/4):int(4*train_images_cartoon.shape[0]/4)]\n",
        "print(train_images_cartoon1.shape)\n",
        "print(train_images_cartoon2.shape)\n",
        "print(train_images_cartoon3.shape)\n",
        "print(train_images_cartoon4.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(small_images_cartoon.shape)\n",
        "small_images_cartoon1=small_images_cartoon[0:int(1*small_images_cartoon.shape[0]/4)]\n",
        "small_images_cartoon2=small_images_cartoon[int(1*small_images_cartoon.shape[0]/4):int(2*small_images_cartoon.shape[0]/4)]\n",
        "small_images_cartoon3=small_images_cartoon[int(2*small_images_cartoon.shape[0]/4):int(3*small_images_cartoon.shape[0]/4)]\n",
        "small_images_cartoon4=small_images_cartoon[int(3*small_images_cartoon.shape[0]/4):int(4*small_images_cartoon.shape[0]/4)]\n",
        "print(small_images_cartoon1.shape)\n",
        "print(small_images_cartoon2.shape)\n",
        "print(small_images_cartoon3.shape)\n",
        "print(small_images_cartoon4.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "BATCH_SIZE_PER_REPLICA = 8\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * 8 #8TPUs\n",
        "\n",
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(resolver)\n",
        "except:\n",
        "  strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "train_images_cartoon1 = tf.data.Dataset.from_tensor_slices((train_images_cartoon1)).batch(GLOBAL_BATCH_SIZE)  \n",
        "train_images_cartoon2 = tf.data.Dataset.from_tensor_slices((train_images_cartoon2)).batch(GLOBAL_BATCH_SIZE) \n",
        "train_images_cartoon3 = tf.data.Dataset.from_tensor_slices((train_images_cartoon3)).batch(GLOBAL_BATCH_SIZE) \n",
        "train_images_cartoon4 = tf.data.Dataset.from_tensor_slices((train_images_cartoon4)).batch(GLOBAL_BATCH_SIZE) \n",
        "train_images_cartoon1 = strategy.experimental_distribute_dataset(train_images_cartoon1)\n",
        "train_images_cartoon2 = strategy.experimental_distribute_dataset(train_images_cartoon2)\n",
        "train_images_cartoon3 = strategy.experimental_distribute_dataset(train_images_cartoon3)\n",
        "train_images_cartoon4 = strategy.experimental_distribute_dataset(train_images_cartoon4)\n",
        "\n",
        "\n",
        "small_images_cartoon1 = tf.data.Dataset.from_tensor_slices((small_images_cartoon1)).batch(GLOBAL_BATCH_SIZE)  \n",
        "small_images_cartoon2 = tf.data.Dataset.from_tensor_slices((small_images_cartoon2)).batch(GLOBAL_BATCH_SIZE) \n",
        "small_images_cartoon3 = tf.data.Dataset.from_tensor_slices((small_images_cartoon3)).batch(GLOBAL_BATCH_SIZE) \n",
        "small_images_cartoon4 = tf.data.Dataset.from_tensor_slices((small_images_cartoon4)).batch(GLOBAL_BATCH_SIZE) \n",
        "small_images_cartoon1 = strategy.experimental_distribute_dataset(small_images_cartoon1)\n",
        "small_images_cartoon2 = strategy.experimental_distribute_dataset(small_images_cartoon2)\n",
        "small_images_cartoon3 = strategy.experimental_distribute_dataset(small_images_cartoon3)\n",
        "small_images_cartoon4 = strategy.experimental_distribute_dataset(small_images_cartoon4)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "\n",
            "(51200, 64, 64, 3)\n",
            "(12800, 64, 64, 3)\n",
            "(12800, 64, 64, 3)\n",
            "(12800, 64, 64, 3)\n",
            "(12800, 64, 64, 3)\n",
            "(51200, 64, 64, 3)\n",
            "(12800, 64, 64, 3)\n",
            "(12800, 64, 64, 3)\n",
            "(12800, 64, 64, 3)\n",
            "(12800, 64, 64, 3)\n",
            "All devices:  []\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA6YBmHTl6Pm"
      },
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=(64,64,3)))\n",
        "    \n",
        "    model.add(layers.Conv2D(128, 5))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(32, 5))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(32, 5))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "    \n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(8*8*16, use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "    \n",
        "    model.add(layers.Reshape((8,8,16)))\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1),padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    \n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2),padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    \n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5),padding=\"same\", strides=(2, 2), use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    \n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    \n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5),padding=\"same\", strides=(2, 2), use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "  \n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    \n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(3,5,padding=\"same\",strides=(1, 1), activation='tanh', use_bias=False))\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Input(shape=(64,64,3)))\n",
        "    \n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(16, (5, 5), strides=(1, 1)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(32, (5, 5), strides=(1, 1)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(1, 1)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(1, 1)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(1, 1)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(1, 1)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "\n",
        "    model.add(layers.Dense(256))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmwSt0nYl7q_",
        "outputId": "cc11b17c-769c-463a-bf6e-291feb4ec14b"
      },
      "source": [
        "with strategy.scope():\n",
        "  discriminator_cartoon = make_discriminator_model()\n",
        "  generator = make_generator_model()\n",
        "\n",
        "  discriminator_cartoon.summary()\n",
        "  generator.summary()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "(None, 64, 64, 3)\n",
            "(None, 60, 60, 16)\n",
            "(None, 56, 56, 32)\n",
            "(None, 52, 52, 128)\n",
            "(None, 48, 48, 128)\n",
            "(None, 44, 44, 128)\n",
            "(None, 40, 40, 128)\n",
            "(None, 256)\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "(None, 60, 60, 128)\n",
            "(None, 56, 56, 32)\n",
            "(None, 52, 52, 32)\n",
            "(None, 1024)\n",
            "(None, 8, 8, 16)\n",
            "(None, 8, 8, 128)\n",
            "(None, 8, 8, 128)\n",
            "(None, 8, 8, 128)\n",
            "(None, 8, 8, 128)\n",
            "(None, 8, 8, 128)\n",
            "(None, 8, 8, 128)\n",
            "(None, 8, 8, 128)\n",
            "(None, 16, 16, 128)\n",
            "(None, 16, 16, 128)\n",
            "(None, 16, 16, 128)\n",
            "(None, 16, 16, 128)\n",
            "(None, 32, 32, 128)\n",
            "(None, 32, 32, 128)\n",
            "(None, 32, 32, 128)\n",
            "(None, 32, 32, 128)\n",
            "(None, 64, 64, 128)\n",
            "(None, 64, 64, 128)\n",
            "(None, 64, 64, 128)\n",
            "(None, 64, 64, 128)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 60, 60, 16)        1216      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 60, 60, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 60, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 56, 56, 32)        12832     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 52, 52, 128)       102528    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 52, 52, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 52, 52, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 48, 48, 128)       409728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 48, 48, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 48, 48, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 44, 44, 128)       409728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 44, 44, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 44, 44, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 40, 40, 128)       409728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 40, 40, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 40, 40, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 204800)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               52429056  \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 53,775,073\n",
            "Trainable params: 53,775,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 60, 60, 128)       9728      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 60, 60, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 60, 60, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 56, 56, 32)        102432    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 56, 56, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 52, 52, 32)        25632     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 52, 52, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 52, 52, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 86528)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              88604672  \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 8, 8, 128)         51200     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 128)         409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 8, 8, 128)         409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 128)         409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 8, 8, 128)         409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 128)         409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 128)       409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 16, 16, 128)       409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 16, 16, 128)       409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 16, 16, 128)       409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 128)       409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 32, 32, 128)       409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 32, 32, 128)       409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 32, 32, 128)       409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 64, 64, 128)       409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 64, 64, 128)       409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 64, 64, 128)       409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 64, 64, 128)       409600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTr (None, 64, 64, 3)         9600      \n",
            "=================================================================\n",
            "Total params: 96,190,656\n",
            "Trainable params: 96,183,360\n",
            "Non-trainable params: 7,296\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leHPhSAxl8oA",
        "outputId": "cbe1f602-961b-4985-d0c2-bafa0c7ffca5"
      },
      "source": [
        "with strategy.scope():\n",
        "# This method returns a helper function to compute cross entropy loss\n",
        "  cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False,reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "  def discriminator_cartoon_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    #print(\"disc_loss:\",total_loss)\n",
        "    return  tf.nn.compute_average_loss(total_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "\n",
        "  def _gaussian_kernel(kernel_size, sigma, n_channels, dtype):\n",
        "    x = tf.range(-kernel_size // 2 + 1, kernel_size // 2 + 1, dtype=dtype)\n",
        "    g = tf.math.exp(-(tf.pow(x, 2) / (2 * tf.pow(tf.cast(sigma, dtype), 2))))\n",
        "    g_norm2d = tf.pow(tf.reduce_sum(g), 2)\n",
        "    g_kernel = tf.tensordot(g, g, axes=0) / g_norm2d\n",
        "    g_kernel = tf.expand_dims(g_kernel, axis=-1)\n",
        "    return tf.expand_dims(tf.tile(g_kernel, (1, 1, n_channels)), axis=-1)\n",
        "\n",
        "\n",
        "  def apply_blur(img):\n",
        "    blur = _gaussian_kernel(17, 30, 3, img.dtype)\n",
        "    img = tf.nn.depthwise_conv2d(img, blur, [1,1,1,1], 'SAME')\n",
        "    return img\n",
        "\n",
        "\n",
        "  def generator_loss(fake_output,norm,genr):\n",
        "\n",
        "    norm=apply_blur(norm)\n",
        "    genr=apply_blur(genr)\n",
        "    total_loss=tf.nn.compute_average_loss(((norm-genr)*(norm-genr)))*0.3+0.7*tf.nn.compute_average_loss((cross_entropy(tf.ones_like(fake_output), fake_output)))\n",
        "   # print(\"gen_loss:\",total_loss)\n",
        "    return  (total_loss)\n",
        "\n",
        "  generator_optimizer = tf.keras.optimizers.Adam(0.000003)\n",
        "  discriminator_cartoon_optimizer = tf.keras.optimizers.Adam(0.00001)\n",
        "\n",
        "  @tf.function\n",
        "  def train_step_cartoon(cartoons,dataset_seed):\n",
        "\n",
        "      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_cartoon_tape :\n",
        "        \n",
        "        generated_images = generator(dataset_seed, training=True)\n",
        "\n",
        "        real_output_cartoon = discriminator_cartoon(cartoons, training=True)\n",
        "\n",
        "        fake_output_cartoon = discriminator_cartoon(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output_cartoon,dataset_seed,generated_images)\n",
        "        \n",
        "        disc_cartoon_loss = discriminator_cartoon_loss(real_output_cartoon, fake_output_cartoon)\n",
        "      \n",
        "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "      gradients_of_discriminator_cartoon = disc_cartoon_tape.gradient(disc_cartoon_loss, discriminator_cartoon.trainable_variables)\n",
        "      \n",
        "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "      \n",
        "      discriminator_cartoon_optimizer.apply_gradients(zip(gradients_of_discriminator_cartoon, discriminator_cartoon.trainable_variables))\n",
        "      \n",
        "        \n",
        "  \n",
        "\n",
        "def train(dataset_seed,dataset_cartoon, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    ii=0\n",
        "    for image_batch in dataset_cartoon:\n",
        "      for seed_batch in dataset_seed:\n",
        "        ii+=1\n",
        "        print(\"\\r\" + str(ii),end=\"\")\n",
        "        strategy.run(train_step_cartoon,args=(image_batch,seed_batch,))\n",
        "      print(\"start test\")\n",
        "      generate_images(generator,test_img)\n",
        "        \n",
        "      \n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "\n",
        "starttime = time.process_time()\n",
        "\n",
        "\n",
        "def generate_images(model, test_input):    \n",
        "  predictions = model(test_input,training=False)\n",
        "  predictions = np.array(predictions)\n",
        "    \n",
        "#  test_input = apply_blur(test_input)\n",
        "  test_input = np.array(test_input,dtype= 'float32')\n",
        "  test_input = (test_input+1)*127.5\n",
        "\n",
        "#  predictions=apply_blur(predictions)\n",
        "\n",
        "  generated_images = np.array(predictions,dtype= 'float32')\n",
        "#  print(generated_images)\n",
        "  generated_images = (generated_images+1)*127.5\n",
        "  cz=0\n",
        "  cz2 =0\n",
        "  heighest = 0\n",
        "  while(True):\n",
        "      heighest +=1\n",
        "      if(os.path.exists(\"outputs/0/\"+str(heighest)+\".jpg\")==False):\n",
        "        break\n",
        "\n",
        "  fig = plt.figure(figsize=(20,10))\n",
        "  for i in generated_images:\n",
        "    plt.subplot(4, 10, cz2+1)\n",
        "    plt.imshow(np.array(cv2.cvtColor(test_input[cz], cv2.COLOR_BGR2RGB),dtype= 'int32'))\n",
        "    plt.subplot(4, 10, cz2+2)\n",
        "    plt.imshow(np.array(cv2.cvtColor(i, cv2.COLOR_BGR2RGB),dtype= 'int32'))\n",
        "    plt.axis('off')\n",
        "    cv2.imwrite(\"outputs/\"+str(cz)+\"/\"+str(heighest)+\".jpg\",i)\n",
        "    cv2.imwrite(\"outputs/\"+str(cz)+\"/\"+str(heighest)+\"_o.jpg\",i)\n",
        "    cz+=1\n",
        "    cz2+=2\n",
        "  \n",
        "  display.clear_output(wait=True)\n",
        "  plt.show()\n",
        "  global starttime\n",
        "  end = time.process_time()\n",
        "  print(end - starttime)\n",
        "  starttime = time.process_time()\n",
        "\n",
        "\n",
        "os.system(\"mkdir outputs\")\n",
        "for i in range(20):\n",
        "  os.system(\"mkdir outputs/\"+str(i))\n",
        "\n",
        "try:\n",
        "  generator.load_weights('gen_weights.h5')\n",
        "  discriminator_cartoon.load_weights('disc_weights.h5')\n",
        "except:\n",
        "  print(\"no model stored\")\n",
        "\n",
        "for i in range(10000):\n",
        "    \n",
        "  train(small_images_cartoon4,train_images_cartoon4, 1)\n",
        "  print(\"save chkp\")\n",
        "  generator.save_weights('gen_weights.h5', overwrite=True)\n",
        "  discriminator_cartoon.save_weights('disc_weights.h5', overwrite=True)\n",
        "  \n",
        "  train(small_images_cartoon3,train_images_cartoon3, 1)\n",
        "  print(\"save chkp\")\n",
        "  generator.save_weights('gen_weights.h5', overwrite=True)\n",
        "  discriminator_cartoon.save_weights('disc_weights.h5', overwrite=True)\n",
        "  \n",
        "  train(small_images_cartoon2,train_images_cartoon2, 1)\n",
        "  print(\"save chkp\")\n",
        "  generator.save_weights('gen_weights.h5', overwrite=True)\n",
        "  discriminator_cartoon.save_weights('disc_weights.h5', overwrite=True)\n",
        "  \n",
        "  train(small_images_cartoon1,train_images_cartoon1, 1)\n",
        "  print(\"save chkp\")\n",
        "  generator.save_weights('gen_weights.h5', overwrite=True)\n",
        "  discriminator_cartoon.save_weights('disc_weights.h5', overwrite=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTzRAODEJKls",
        "outputId": "536c68af-b1d3-4c9c-c196-241fc98f105c"
      },
      "source": [
        "print(\"save chkp\")\n",
        "generator.save_weights('gen_weights.h5', overwrite=True)\n",
        "discriminator_cartoon.save_weights('disc_weights.h5', overwrite=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "save chkp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6oKyMs2lXga"
      },
      "source": [
        "try:\n",
        "  generator.load_weights('gen_weights.h5')\n",
        "  discriminator_cartoon.load_weights('disc_weights.h5')\n",
        "except:\n",
        "  print(\"no model stored\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "xDLNAGTNpMQx",
        "outputId": "f919d217-1e9d-4daf-8bd4-36f6d5a731b5"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def generate_image(model, filename):    \n",
        "  small_images_cartoon=[]\n",
        "  img = cv2.imread(filename)\n",
        "  img3 = cv2.resize(img, (64,64))\n",
        "  img3 = cv2.blur(img3,(7,7))\n",
        "  small_images_cartoon.append(img3)\n",
        "  small_images_cartoon = np.array(small_images_cartoon,dtype=object)\n",
        "  small_images_cartoon = small_images_cartoon.reshape(small_images_cartoon.shape[0], 64, 64, 3).astype('float32')\n",
        "  small_images_cartoon = (small_images_cartoon - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
        "\n",
        "  predictions = model(small_images_cartoon,training=False)\n",
        "  generated_images = np.array(predictions,dtype= 'float32')\n",
        "  generated_images = (generated_images+1)*127.5\n",
        "\n",
        "  cv2_imshow(img)\n",
        "  cv2_imshow(generated_images[0])\n",
        "\n",
        "generate_image(generator,\"Unbenannt3.png\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAC2ElEQVR4nO2azU0zQQyGJysKQLmS3EgPdEEVEQ1QBg0gqqALeuCYcCSiApaDkXHsscfzxyjSvvoOm91N9nltj2dn+FbzPIdL1jQaoFaLgdFaDIzWxRu4Gvv403bnuW19eNcu9TJw2u60pzqhUfg77ItwvosBDRHOrw/vWR7wZhoRPNneAFLKh0U/agKfRvGAVm1fJSicP9IGJfXAfhwOWhqQuFr50quaSfpdIxtdDORWuUdalrINyBIPehSnt6fvu0eJ8vXxCsfXN/cFj6PKM5BFLzW9PcmTHg8t5wGjvVBRVpkEKshG0oamDAMsEkbZlKFosjup910oSV/JjaMiVy4DrBkDPSXGY8NG0mGZh7QBGmw8hvbCCr158XiUMEDbDuYBQe3R6b+nRpYBOY2ftjuIfafwF1SRaoBO4JiHaHNMJqRracUnMsoNgumTQlNcQJR5kCY9ypoTIhmw6ZE1Sf8/OjMALRLrHg7YPEJBi4mfN3v8J69mjQSeAdpw0Az7RQw/mrHDzy4B9MPx5eH44gdNG0Dc6DuCHKB07PpTQUMeDX+u+LsQ0tPwAyLzILkpEEZX84Y3P2/2NamYGC4KPwK3xKXFI6sZPiYzU19FfBAzG1D9svOAmCssaz9WfRWt5nlmQ5baoL0/KjCgcRQH2D8V8C4UHcFaJRgVUlMbeROZvea3vmnWd5MO49Hqc3Mbznc42MIlujAPenevZ8rKQHpJ6aEPjdBD/uJ4Cvqis/neTlIFS3vrdTqce6t/Beoha0FD30m1kdBQZTsrZ+9CIVZObBbrFP5e+0K/3Sn8rQRyJfupHO7F9EEzUD98kTvZnWroAzMQbUdyF8ij3tyoSAaiWymhYvOMqRU6yLut0uTB1zf3bekD3ZWQK7JoRRXkoTk0lZoBbXrOjWJX+kANsM0IW06s3vSh+V8p/18X/38lFgOjtRgYrcXAaC0GRmsxMFqLgdG6eAM/rvrsTAjAr0cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F3F06CFF9D0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F3F06CFF9D0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}