{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1eXfLKRG93Qfi0Ui1snmgVO6989fr8I26",
      "authorship_tag": "ABX9TyOY/VuWO9Pm9wa+p2YznMrv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dercodeKoenig/colab-KI/blob/main/gan-TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4wZc9dPOqzP",
        "outputId": "2b8e8e1a-31f8-4d71-a47c-2f7e035c7c6e"
      },
      "source": [
        "\n",
        "%cd /content/drive/MyDrive/\n",
        "#!rm -r *\n",
        "!git clone https://github.com/dercodeKoenig/cartoon-faces.git\n",
        "#!apt-get update -y\n",
        "#!apt-get install libgl-dev -y\n",
        "#!pip install tensorflow opencv-python numpy\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import cv2\n",
        "from IPython import display\n",
        "\n",
        "try:\n",
        "  train_images_cartoon = np.load(\"npfile.npy\")\n",
        "except:\n",
        "\n",
        "  train_images_cartoon = []\n",
        "  z=0\n",
        "  total = len(os.listdir(\"cartoon-faces\"))\n",
        "  max=512*100\n",
        "  files = os.listdir(\"cartoon-faces\")\n",
        "  while(True):\n",
        "    if(z==max):\n",
        "      break\n",
        "    try:\n",
        "      img = cv2.imread(\"cartoon-faces/\"+files[z])\n",
        "      img1 = img.copy()\n",
        "      img2 = cv2.resize(img1, (64,64))\n",
        "      train_images_cartoon.append(img2)\n",
        "      print(\"\\r\" + str(z) + \" / \" + str(51200),end=\"\")\n",
        "    except:\n",
        "      print(\"\")\n",
        "      try:\n",
        "        print(\"error: cartoon-faces/\"+files[z])\n",
        "      except:\n",
        "        break\n",
        "      max+=1\n",
        "    z+=1\n",
        "\n",
        "  print(\"\")\n",
        "\n",
        "  train_images_cartoon = np.array(train_images_cartoon,dtype=object)\n",
        "\n",
        "\n",
        "  train_images_cartoon = train_images_cartoon.reshape(train_images_cartoon.shape[0], 64, 64, 3).astype('float32')\n",
        "  train_images_cartoon = (train_images_cartoon - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
        "  np.save(\"npfile\", train_images_cartoon)\n",
        "\n",
        "print(train_images_cartoon.shape)\n",
        "train_images_cartoon1=train_images_cartoon[0:int(1*train_images_cartoon.shape[0]/4)]\n",
        "train_images_cartoon2=train_images_cartoon[int(1*train_images_cartoon.shape[0]/4):int(2*train_images_cartoon.shape[0]/4)]\n",
        "train_images_cartoon3=train_images_cartoon[int(2*train_images_cartoon.shape[0]/4):int(3*train_images_cartoon.shape[0]/4)]\n",
        "train_images_cartoon4=train_images_cartoon[int(3*train_images_cartoon.shape[0]/4):int(4*train_images_cartoon.shape[0]/4)]\n",
        "print(train_images_cartoon1.shape)\n",
        "print(train_images_cartoon2.shape)\n",
        "print(train_images_cartoon3.shape)\n",
        "print(train_images_cartoon4.shape)\n",
        "\n",
        "\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * 8 #8TPUs\n",
        "\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "\n",
        "train_images_cartoon1 = tf.data.Dataset.from_tensor_slices((train_images_cartoon1)).batch(GLOBAL_BATCH_SIZE)  \n",
        "train_images_cartoon2 = tf.data.Dataset.from_tensor_slices((train_images_cartoon2)).batch(GLOBAL_BATCH_SIZE) \n",
        "train_images_cartoon3 = tf.data.Dataset.from_tensor_slices((train_images_cartoon3)).batch(GLOBAL_BATCH_SIZE) \n",
        "train_images_cartoon4 = tf.data.Dataset.from_tensor_slices((train_images_cartoon4)).batch(GLOBAL_BATCH_SIZE) \n",
        "train_images_cartoon1 = strategy.experimental_distribute_dataset(train_images_cartoon1)\n",
        "train_images_cartoon2 = strategy.experimental_distribute_dataset(train_images_cartoon2)\n",
        "train_images_cartoon3 = strategy.experimental_distribute_dataset(train_images_cartoon3)\n",
        "train_images_cartoon4 = strategy.experimental_distribute_dataset(train_images_cartoon4)\n",
        "\n",
        "\n",
        "\n",
        "del train_images_cartoon\n",
        "#display.clear_output()\n",
        "\n",
        "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=(100)))\n",
        "\n",
        "    model.add(layers.Dense(8*8*82,use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "    \n",
        "    model.add(layers.Reshape((8,8,82)))\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    \n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(1, 1),padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    \n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2),padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    \n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5),padding=\"same\", strides=(2, 2), use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    \n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5),padding=\"same\", strides=(2, 2), use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2D(128, 5,padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(3,5,padding=\"same\",strides=(1, 1), activation='tanh', use_bias=False))\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Input(shape=(64,64,3)))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(1, 1)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(1, 1)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(1, 1)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(1, 1)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(256, (5, 5), strides=(1, 1)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Conv2D(512, (5, 5), strides=(1, 1)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    model.add(layers.Dense(256))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Dense(128))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    print(model.output_shape)\n",
        "\n",
        "    model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "with strategy.scope():\n",
        "  # Set reduction to `none` so we can do the reduction afterwards and divide by\n",
        "  # global batch size.\n",
        "  cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False,reduction=tf.keras.losses.Reduction.NONE)\n",
        "      \n",
        "\n",
        "  def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    #print(\"disc_loss:\",total_loss)\n",
        "    return tf.nn.compute_average_loss(total_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "  \n",
        "  def generator_loss(fake_output):\n",
        "    total_loss=cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "    #print(\"gen_loss:\",total_loss)\n",
        "    return tf.nn.compute_average_loss(total_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "# model, optimizer, and checkpoint must be created under `strategy.scope`.\n",
        "with strategy.scope():\n",
        "  discriminator = make_discriminator_model()\n",
        "  generator = make_generator_model()\n",
        "  generator_optimizer = tf.keras.optimizers.Adam(0.00001)\n",
        "  discriminator_optimizer = tf.keras.optimizers.Adam(0.00002)\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE_PER_REPLICA, 100])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    print(gen_loss,disc_loss)\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "display.clear_output()\n",
        "\n",
        "seed = tf.random.normal([20, 100])\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    zzz=0\n",
        "    for image_batch in dataset:\n",
        "      zzz+=1\n",
        "      strategy.run(train_step, args=(image_batch,))\n",
        "\n",
        "      if(zzz==10):\n",
        "        zzz=0\n",
        "        generate_images(generator,epoch + 1,seed)\n",
        "\n",
        "    \n",
        "    print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "def generate_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  generated_images = np.array(predictions,dtype= 'float32')\n",
        "  generated_images = (generated_images+1)*127.5\n",
        "  cz=0\n",
        "\n",
        "  heighest = 0\n",
        "  while(True):\n",
        "      heighest +=1\n",
        "      if(os.path.exists(\"outputs/0/\"+str(heighest)+\".jpg\")==False):\n",
        "        break\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  for i in generated_images:\n",
        "    #print(np.array(i,dtype= 'int32'))\n",
        "    plt.subplot(4, 5, cz+1)\n",
        "    plt.imshow(np.array(cv2.cvtColor(i, cv2.COLOR_BGR2RGB),dtype= 'int32'))\n",
        "    plt.axis('off')\n",
        "    cv2.imwrite(\"outputs/\"+str(cz)+\"/\"+str(heighest)+\".jpg\",i)\n",
        "    cz+=1\n",
        "  display.clear_output(wait=True)\n",
        "  plt.show()\n",
        "\n",
        "os.system(\"mkdir outputs\")\n",
        "for i in range(20):\n",
        "  os.system(\"mkdir outputs/\"+str(i))\n",
        "\n",
        "\n",
        "try:\n",
        "  generator.load_weights('gen_weights.h5')\n",
        "  discriminator.load_weights('disc_weights.h5')\n",
        "except:\n",
        "  print(\"no weights\")\n",
        "\n",
        "for i in range(10000):\n",
        "  train(train_images_cartoon1, 1)\n",
        "  train(train_images_cartoon2, 1)\n",
        "  train(train_images_cartoon3, 1)\n",
        "  train(train_images_cartoon4, 1)\n",
        "  if(i%10==0):\n",
        "    print(\"save chkp\")\n",
        "    generator.save_weights('gen_weights.h5', overwrite=True)\n",
        "    discriminator.save_weights('disc_weights.h5', overwrite=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "fatal: destination path 'cartoon-faces' already exists and is not an empty directory.\n",
            "(24830, 64, 64, 3)\n",
            "(6207, 64, 64, 3)\n",
            "(6208, 64, 64, 3)\n",
            "(6207, 64, 64, 3)\n",
            "(6208, 64, 64, 3)\n",
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n",
            "WARNING:tensorflow:TPU system grpc://10.83.142.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.83.142.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.83.142.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.83.142.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 8\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(None, 64, 64, 3)\n",
            "(None, 60, 60, 64)\n",
            "(None, 56, 56, 64)\n",
            "(None, 52, 52, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH6B7PhNOwsV",
        "outputId": "cabd8421-0e0c-443f-a7c4-10e89aedfb52"
      },
      "source": [
        "import os\n",
        "from tensorflow.python.profiler import profiler_client\n",
        "\n",
        "tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8470', '8466')\n",
        "print(profiler_client.monitor(tpu_profile_service_address, 100, 2))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Timestamp: 14:44:11\n",
            "  TPU type: TPU v2\n",
            "  Utilization of TPU Matrix Units (higher is better): 0.000%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}