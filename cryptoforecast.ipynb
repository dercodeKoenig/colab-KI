{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Train**","metadata":{}},{"cell_type":"markdown","source":"We want to predict the change of the price of crypto a few minutes in the future based on the prices of past minutes. <br>\nThe dataset is generated with binance-api. Code for dataset generation will be on github soon.<br>\n(https://github.com/dercodeKoenig/crypto-forecast-jupyterlab)<br>\nData looks like this:<br>\n[<br>\n    &nbsp;&nbsp;&nbsp;[date, time, open, high, low, close, volume],<br>\n    &nbsp;&nbsp;&nbsp;[date, time, open, high, low, close, volume],<br>\n    &nbsp;&nbsp;&nbsp;...<br>\n    &nbsp;&nbsp;&nbsp;[date, time, open, high, low, close, volume],<br>\n ]<br>\nThere is one entry for each minute<br>\n\nLets put it into a neural network and start trading. $$$","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output\nimport numpy as np\nimport tensorflow as tf\nimport copy\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I uploaded a dataset on kaggle. It contains all Prices for the listed Symbols.<br>\nWe only need to choose one.","metadata":{}},{"cell_type":"code","source":"datadir = \"../input/ethusdt01012018/\"\n\nvalid_symbols = ['ETHUSDT', 'AAVEUSDT', 'ADAUSDT', 'ADXUSDT', 'AIONUSDT', 'AVAXUSDT', 'AXSUSDT', 'BATUSDT', 'BLZUSDT', 'BNBUSDT', 'BNTUSDT', 'CHRUSDT', 'CVCUSDT', 'DASHUSDT', 'DATAUSDT', 'DENTUSDT', 'DEXEUSDT', 'DOTUSDT', 'ELFUSDT', 'ENJUSDT', 'EOSUSDT', 'ETCUSDT', 'FIROUSDT', 'FTMUSDT', 'FUNUSDT', 'GALAUSDT', 'GHSTUSDT', 'GRTUSDT', 'GXSUSDT', 'HOTUSDT', 'ICXUSDT', 'IOSTUSDT', 'IOTAUSDT', 'IOTXUSDT', 'KEYUSDT', 'KMDUSDT', 'KNCUSDT', 'LINKUSDT', 'LRCUSDT', 'LSKUSDT', 'LTCUSDT', 'MANAUSDT', 'MATICUSDT', 'MFTUSDT', 'MTLUSDT', 'NANOUSDT', 'NEOUSDT', 'OMGUSDT', 'ONTUSDT', 'POWRUSDT', 'PUNDIXUSDT', 'REPUSDT', 'RLCUSDT', 'SANDUSDT', 'SCUSDT', 'SOLUSDT', 'STRAXUSDT', 'THETAUSDT', 'TRXUSDT', 'VETUSDT', 'VGXUSDT', 'WANUSDT', 'WAVESUSDT', 'XEMUSDT', 'XLMUSDT', 'XMRUSDT', 'XRPUSDT', 'XVGUSDT', 'ZECUSDT', 'ZENUSDT', 'ZILUSDT', 'ZRXUSDT']\n\nprint(len(valid_symbols),\"symbols found\")\nsymbol = valid_symbols[0]\nprint(\"woking on\", symbol)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How does our Model work?\nWe will use a combination of cnn and rnn. First we do some conv1d, appending some GRUs and finally we get the predictions in dense layers.<br>\nThe input for the model will look like this:<br>\n\nbatches[<br>\n&nbsp;&nbsp;&nbsp;&nbsp;samples[<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[feature1, feature2, feature3 ...]<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[feature1, feature2, feature3 ...]<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[feature1, feature2, feature3 ...]<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[feature1, feature2, feature3 ...]<br>\n&nbsp;&nbsp;&nbsp;&nbsp;[<br>\n<br>\n&nbsp;&nbsp;&nbsp;&nbsp;samples[<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[feature1, feature2, feature3 ...]<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[feature1, feature2, feature3 ...]<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[feature1, feature2, feature3 ...]<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[feature1, feature2, feature3 ...]<br>\n&nbsp;&nbsp;&nbsp;&nbsp;[<br>\n]<br>\n\nIn this batch we have 2 objects with 4 samples for each object. This would be the past 4 minutes to predict the next price change.<br><br>\nOnly 4 minutes will not be enough to make acceptable predictions so we will make the sequence length a bit longer. Lets say we want the model to look for the past 3 days:<br>\nseq_len = 3days * 24 hours per day * 60 minutes per hour<br>\n\nbatch size is the number of training objects to analyse before performing gradient descent<br>\nlooks_in_future is the number of minutes we want to look into the future.<br>\n\n# What do we predict?\nWhat the model will predict is not the absolute price, it is the change of the price. This is because neurons cant give us a useable number like 3000$, but they can give us a change in price, like 3% price increase in the next 50 minutes<br><br>\n\n# More on the input data:\nWe will input 7 features into the model:<br>\n* open price change = the change of the price where the minute started\n* high price change = the change of the maximum price reached in this minute\n* low price change = the change of the lowest price reached in this minute\n* close price change = the change of the price at the end of this minute\n* volume change = the change of the volume traded (i think it should be this)\n* relative to ath max = maximum price reached this minute relative to the last all-time-high\n* relative to ath min = minumum price reached this minute relative to the last all-time-high\n<br><br>\nlets say we have a sequence len of 2 and the last ath was 50: we need 3 entrys<br>\n<table>\n  <tr>\n    <th>date</th>\n    <th>time</th>\n    <th>open</th>\n    <th>high</th>\n    <th>low</th>\n    <th>close</th>\n    <th>volume</th>\n  </tr>\n  <tr>\n    <td>1.1.18</td>\n    <td>00:01:00</td>\n    <td>30</td>\n    <td>35</td>\n    <td>28</td>\n    <td>29</td>\n    <td>100</td>\n  </tr>\n    <tr>\n    <td>1.1.18</td>\n    <td>00:02:00</td>\n    <td>29</td>\n    <td>30</td>\n    <td>25</td>\n    <td>26</td>\n    <td>120</td>\n  </tr>\n  <tr>\n    <td>1.1.18</td>\n    <td>00:03:00</td>\n    <td>26</td>\n    <td>30</td>\n    <td>26</td>\n    <td>29</td>\n    <td>80</td>\n  </tr>\n</table>\nour input sequence should be like this:\n<table>\n  <tr>\n    <th>open_change</th>\n    <th>high_change</th>\n    <th>low_change</th>\n    <th>close_change</th>\n    <th>volume_change</th>\n    <th>price_high_relative</th>\n    <th>price_low_relative</th>\n  </tr>\n   <tr>\n    <td>-0.03</td>\n    <td>-0.14</td>\n    <td>-0.1</td>\n    <td>-0.1</td>\n    <td>0.2</td>\n    <td>0.6</td>\n    <td>0.5</td>\n  </tr>\n   <tr>\n    <td>-0.1</td>\n    <td>0</td>\n    <td>0.04</td>\n    <td>0.1</td>\n    <td>-0.16</td>\n    <td>0.6</td>\n    <td>0.52</td>\n  </tr>\n \n</table>","metadata":{}},{"cell_type":"markdown","source":"# The Output:\nfor the specified minutes to forecast we will predict the highest and the lowest value to be reached relative to the last sample in the input sequence","metadata":{}},{"cell_type":"code","source":"seq_len = int(24*3*60)\nbatch_size = 32\nlearnrate = 0.000005\nlooks_in_future = 20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load the data\nnpd = np.load(datadir+symbol+\".npy\",allow_pickle=True)\nprint(\"loaded:\", npd.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T18:31:10.747298Z","iopub.execute_input":"2021-12-20T18:31:10.747582Z","iopub.status.idle":"2021-12-20T18:31:13.127469Z","shell.execute_reply.started":"2021-12-20T18:31:10.747531Z","shell.execute_reply":"2021-12-20T18:31:13.126706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for each entry we are calculating the maximum price this crypto reached until than\nall_time_high = []\nlast_max_val = 0\nfor i in tqdm(range(1,npd.shape[0])):\n    current_val = float(npd[i][3])\n    if(current_val > last_max_val):\n        last_max_val = current_val\n    \n    all_time_high.append(last_max_val)\n\nprint(\"\")\nplt.title(\"all-time-high values for each entry\")\nplt.plot(all_time_high)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T18:31:13.130621Z","iopub.execute_input":"2021-12-20T18:31:13.13083Z","iopub.status.idle":"2021-12-20T18:31:16.540286Z","shell.execute_reply.started":"2021-12-20T18:31:13.130802Z","shell.execute_reply":"2021-12-20T18:31:16.538842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"npd_relative = []\nprint(\"converting to relative data...\")\n\nprices_relative_to_ath_max = []\nprices_relative_to_ath_min = []\n\nrelative_price_changes_max = []\nrelative_price_changes_min = []\n\nfor i in tqdm(range(npd.shape[0]-1)):\n    #changes, append *10 for numbers to note be too small\n    price_open  = (float(npd[i+1][2])-float(npd[i][2]))/float(npd[i][2])*10\n    price_high  = (float(npd[i+1][3])-float(npd[i][3]))/float(npd[i][3])*10\n    price_low   = (float(npd[i+1][4])-float(npd[i][4]))/float(npd[i][4])*10\n    price_close = (float(npd[i+1][5])-float(npd[i][5]))/float(npd[i][5])*10\n    volume = 0\n    if float(npd[i][6]) > 0:\n        volume = (float(npd[i+1][6])-float(npd[i][6]))/float(npd[i][6])\n        \n    #max/min price in price / ath\n    price_relative_ath_max = float(npd[i+1][3]) / all_time_high[i]\n    price_relative_ath_min = float(npd[i+1][4]) / all_time_high[i]\n    \n    prices_relative_to_ath_max.append(price_relative_ath_max)\n    prices_relative_to_ath_min.append(price_relative_ath_min)\n    relative_price_changes_min.append(price_high)\n    relative_price_changes_max.append(price_low)\n    \n    npd_relative.append((price_open, price_high, price_low, price_close, volume, price_relative_ath_max, price_relative_ath_min))\n    \nnpd = np.array(npd_relative,dtype=\"float32\")","metadata":{"execution":{"iopub.status.busy":"2021-12-20T18:31:16.541663Z","iopub.execute_input":"2021-12-20T18:31:16.541907Z","iopub.status.idle":"2021-12-20T18:31:54.262099Z","shell.execute_reply.started":"2021-12-20T18:31:16.541873Z","shell.execute_reply":"2021-12-20T18:31:54.261336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1,ax2) = plt.subplots(2,1, figsize=(15,5))\nax1.set_title(\"relative high/low values\")\nax1.plot(prices_relative_to_ath_min, color=\"red\")\nax1.plot(prices_relative_to_ath_max, color=\"green\")\n\nax2.set_title(\"changes in price (high/low)\")\nax2.plot(relative_price_changes_min, color=\"red\")\nax2.plot(relative_price_changes_max, color=\"green\")\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T18:31:54.264251Z","iopub.execute_input":"2021-12-20T18:31:54.264764Z","iopub.status.idle":"2021-12-20T18:31:56.828914Z","shell.execute_reply.started":"2021-12-20T18:31:54.264723Z","shell.execute_reply":"2021-12-20T18:31:56.828225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unpack_batch(batch):\n    X=[]\n    Y=[]\n    for i in batch:\n            X.append(i[0])\n            Y.append(i[1])\n    X = np.array(X,dtype=\"float32\")\n    Y = np.array(Y,dtype=\"float32\")\n    \n    return (X, Y)\n          \ndef array_to_samples(ar):\n    samples = []\n    l = ar.shape[0]-seq_len-looks_in_future\n    \n    for i in range(l):\n        array_future_data = ar[i+seq_len+1:i+seq_len+1+looks_in_future]\n        maxval = np.amax(array_future_data, axis=0)[5]\n        minval = np.amin(array_future_data, axis=0)[6]\n        \n        # again *10 for same reason\n        maxval_relative = (maxval - ar[i+seq_len][5]) /ar[i+seq_len][5]*10\n        minval_relative = (minval - ar[i+seq_len][6]) /ar[i+seq_len][6]*10\n        \n        data = (ar[i:i+seq_len],(maxval_relative,minval_relative))\n        samples.append(np.array(data,dtype=object))\n    \n    return np.array(samples,dtype=object)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T18:31:56.84305Z","iopub.execute_input":"2021-12-20T18:31:56.843254Z","iopub.status.idle":"2021-12-20T18:31:56.85386Z","shell.execute_reply.started":"2021-12-20T18:31:56.843231Z","shell.execute_reply":"2021-12-20T18:31:56.853172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples_len = npd.shape[0] - seq_len - looks_in_future\nbatch_num = int(samples_len / batch_size)\nprint(\"number of batches:\",batch_num)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T18:31:56.855157Z","iopub.execute_input":"2021-12-20T18:31:56.85551Z","iopub.status.idle":"2021-12-20T18:31:56.863521Z","shell.execute_reply.started":"2021-12-20T18:31:56.855475Z","shell.execute_reply":"2021-12-20T18:31:56.862616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l_in = tf.keras.layers.Input(shape=(seq_len,7), batch_size=batch_size)\n\nc1 = tf.keras.layers.Conv1D(64,16,activation=\"relu\")(l_in)\np1 = tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)(c1)\n\nc2 = tf.keras.layers.Conv1D(128,8,activation=\"relu\")(p1)\np2 = tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)(c2)\n\nc3 = tf.keras.layers.Conv1D(256,4,activation=\"relu\")(p2)\np3 = tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)(c3)\n\nc4 = tf.keras.layers.Conv1D(512,2,activation=\"relu\")(p3)\np4 = tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)(c4)\n\nc5 = tf.keras.layers.Conv1D(32,1,activation=\"relu\")(p4)\np5 = tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)(c5)\n\nrn1 = tf.keras.layers.LSTM(512, return_sequences=False)(p5)\n\nflat = tf.keras.layers.Flatten()(rn1)\nd1 = tf.keras.layers.Dense(512, activation=\"tanh\")(flat)\nd2 = tf.keras.layers.Dense(256, activation=\"tanh\")(d1)\nl_out = tf.keras.layers.Dense(2, activation=\"tanh\")(d2)\n\nmodel = tf.keras.Model(l_in, l_out)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T18:31:56.865186Z","iopub.execute_input":"2021-12-20T18:31:56.865458Z","iopub.status.idle":"2021-12-20T18:31:57.801891Z","shell.execute_reply.started":"2021-12-20T18:31:56.865401Z","shell.execute_reply":"2021-12-20T18:31:57.801204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learnrate)\n\nlosses = []\nct = 0\n\n\ny_true_vals = []\ny_output_vals = []\n\nt0 = time.time()\nfor s in range(batch_num):\n    curr_batch = npd[s * batch_size: (s + 1) * batch_size + seq_len + looks_in_future]\n    samples = array_to_samples(curr_batch)\n    X, Y = unpack_batch(samples)\n\n    with tf.GradientTape() as tape:\n        outputs = model(X)\n        loss = tf.keras.losses.mse(Y,outputs)\n    \n    \n    gradients = tape.gradient(loss,model.trainable_variables)\n    opt.apply_gradients(zip(gradients,model.trainable_variables))\n   \n    for i in Y:\n        y_true_vals.append(i[0])\n    for i in outputs:\n        y_output_vals.append(i[0])\n    losses.append(tf.nn.compute_average_loss(loss).numpy())\n    \n    ct+=1\n    if(ct%100==0):\n        clear_output()\n        plt.figure(figsize=(22,4))\n        plt.plot(losses)\n        plt.show()\n        \n        plt.figure(figsize=(22,4))\n        plt.plot(y_true_vals, color = \"green\")\n        plt.plot(y_output_vals, color = \"red\")\n        plt.show()\n        \n    t1 = time.time()\n    past = t1-t0\n    t0 = t1\n    print(\"\\r\",s,\"/\",batch_num, \":\", str(past)+\"s   (\"+str((batch_num-s)*past)+\"s left)\", end=\"\")\n\n        \nclear_output()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T18:31:57.804018Z","iopub.execute_input":"2021-12-20T18:31:57.804265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(22,4))\n_=plt.plot(losses)\nplt.show()\n\nplt.figure(figsize=(22,4))\n_=plt.plot(y_true_vals, color = \"green\")\n_=plt.plot(y_output_vals, color = \"red\")\nplt.show()\n\n\nmodel.save_weights(symbol)\n\nnp.save(\"y_true_vals\",np.array(y_true_vals))\nnp.save(\"y_output_vals\",np.array(y_output_vals))\nnp.save(\"losses\",np.array(losses))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}